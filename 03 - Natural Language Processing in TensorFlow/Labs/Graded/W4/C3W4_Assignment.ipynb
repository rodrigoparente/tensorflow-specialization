{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "bFWbEb6uGbN-"
   },
   "source": [
    "# Week 4: Predicting the next word\n",
    "\n",
    "Welcome to this assignment! During this week you saw how to create a model that will predict the next word in a text sequence, now you will implement such model and train it using a corpus of [Shakespeare Sonnets](https://www.opensourceshakespeare.org/views/sonnets/sonnet_view.php?range=viewrange&sonnetrange1=1&sonnetrange2=154), while also creating some helper functions to pre-process the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "#### TIPS FOR SUCCESSFUL GRADING OF YOUR ASSIGNMENT:\n",
    "\n",
    "- All cells are frozen except for the ones where you need to submit your solutions or when explicitly mentioned you can interact with it.\n",
    "\n",
    "\n",
    "- You can add new cells to experiment but these will be omitted by the grader, so don't rely on newly created cells to host your solution code, use the provided places for this.\n",
    "- You can add the comment # grade-up-to-here in any graded cell to signal the grader that it must only evaluate up to that point. This is helpful if you want to check if you are on the right track even if you are not done with the whole assignment. Be sure to remember to delete the comment afterwards!\n",
    "- Avoid using global variables unless you absolutely have to. The grader tests your code in an isolated environment without running all cells from the top. As a result, global variables may be unavailable when scoring your submission. Global variables that are meant to be used will be defined in UPPERCASE.\n",
    "\n",
    "- To submit your notebook, save it and then click on the blue submit button at the beginning of the page.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "BOwsuGQQY9OL",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import unittests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Defining some useful global variables\n",
    "\n",
    "Next you will define some global variables that will be used throughout the assignment. Feel free to reference them in the upcoming exercises:\n",
    "\n",
    "- `FILE_PATH`: The file path where the sonnets file is located. \n",
    "\n",
    "- `NUM_BATCHES`: Number of batches. Defaults to 16.\n",
    "- `LSTM_UNITS`: Number of LSTM units in the LSTM layer.\n",
    "- `EMBEDDING_DIM`: Number of dimensions in the embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "FILE_PATH = './data/sonnets.txt'\n",
    "NUM_BATCHES = 16\n",
    "LSTM_UNITS = 128\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A note about grading:**\n",
    "\n",
    "**When you submit this assignment for grading these same values for these globals will be used so make sure that all your code works well with these values. After submitting and passing this assignment, you are encouraged to come back here and play with these parameters to see the impact they have in the classification process. Since this next cell is frozen, you will need to copy the contents into a new cell and run it to overwrite the values for these globals.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Reading the dataset\n",
    "\n",
    "For this assignment you will be using the [Shakespeare Sonnets Dataset](https://www.opensourceshakespeare.org/views/sonnets/sonnet_view.php?range=viewrange&sonnetrange1=1&sonnetrange2=154), which contains more than 2000 lines of text extracted from Shakespeare's sonnets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Pfd-nYKij5yY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2159 lines of sonnets\n",
      "\n",
      "The first 5 lines look like this:\n",
      "\n",
      "from fairest creatures we desire increase,\n",
      "that thereby beauty's rose might never die,\n",
      "but as the riper should by time decease,\n",
      "his tender heir might bear his memory:\n",
      "but thou, contracted to thine own bright eyes,\n"
     ]
    }
   ],
   "source": [
    "# Read the data\n",
    "with open(FILE_PATH) as f:\n",
    "    data = f.read()\n",
    "\n",
    "# Convert to lower case and save as a list\n",
    "corpus = data.lower().split(\"\\n\")\n",
    "\n",
    "print(f\"There are {len(corpus)} lines of sonnets\\n\")\n",
    "print(f\"The first 5 lines look like this:\\n\")\n",
    "for i in range(5):\n",
    "  print(corpus[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "imB15zrSNhA1"
   },
   "source": [
    "## Exercise 1: fit_vectorizer\n",
    "\n",
    "In this exercise, you will use the [tf.keras.layers.TextVectorization layer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) to tokenize and transform the text into numeric values. \n",
    "\n",
    "Note that in this case you will not pad the sentences right now as you've done before, because you need to build the n-grams before padding, so pay attention with the appropriate arguments passed to the TextVectorization layer!\n",
    "\n",
    "**Note**:\n",
    "- You should remove the punctuation and use only lowercase words, so you must pass the correct argument to TextVectorization layer.\n",
    "\n",
    "- In this case you will not pad the sentences with the TextVectorization layer as you've done before, because you need to build the n-grams before padding. Remember that by default, the TextVectorization layer will return a Tensor and therefore every element in it must have the same size, so if you pass two sentences of different length to be parsed, they will be padded. If you do not want to do that, you need to either pass the parameter ragged=True, or pass only a single sentence at the time. Later on in the assignment you will build the n-grams and depending on how you will iterate over the sentences, this may be important. If you choose to first pass the entire corpus to the TextVectorization and then perform the iteration, then you should pass ragged=True, otherwise, if you use the TextVectorization on each sentence separately, then you should not worry about it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "def fit_vectorizer(corpus):\n",
    "    \"\"\"\n",
    "    Instantiates the vectorizer class on the corpus\n",
    "    \n",
    "    Args:\n",
    "        corpus (list): List with the sentences.\n",
    "    \n",
    "    Returns:\n",
    "        (tf.keras.layers.TextVectorization): an instance of the TextVectorization class containing the word-index dictionary, adapted to the corpus sentences.\n",
    "    \"\"\"    \n",
    "\n",
    "    tf.keras.utils.set_random_seed(65) # Do not change this line or you may have different expected outputs throughout the assignment\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    # Define the object\n",
    "    vectorizer = tf.keras.layers.TextVectorization(\n",
    "        ragged=True,\n",
    "        standardize='lower_and_strip_punctuation'\n",
    "    ) \n",
    "    \n",
    "    # Adapt it to the corpus\n",
    "    vectorizer.adapt(corpus)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of words in corpus (including the out of vocabulary): 3189\n"
     ]
    }
   ],
   "source": [
    "vectorizer = fit_vectorizer(corpus)\n",
    "total_words = len(vectorizer.get_vocabulary())\n",
    "print(f\"Total number of words in corpus (including the out of vocabulary): {total_words}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "Total number of words in corpus (including the out of vocabulary): 3189\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77-0sA46OETa"
   },
   "source": [
    "One thing to note is that you can either pass a string or a list of strings to vectorizer. If you pass the former, it will return a *tensor* whereas if you pass the latter, it will return a *ragged tensor* if you've correctly configured the TextVectorization layer to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "tqhPxdeXlfjh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passing a string directly: <tf.Tensor: shape=(5,), dtype=int64, numpy=array([  29,   14,   18,    1, 1679])>\n",
      "Passing a list of strings: <tf.RaggedTensor [[29, 14, 18, 1, 1679]]>\n"
     ]
    }
   ],
   "source": [
    "print(f\"Passing a string directly: {vectorizer('This is a test string').__repr__()}\")\n",
    "print(f\"Passing a list of strings: {vectorizer(['This is a test string'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "Passing a string directly: <tf.Tensor: shape=(5,), dtype=int64, numpy=array([  29,   14,   18,    1, 1679])>\n",
    "Passing a list of strings: <tf.RaggedTensor [[29, 14, 18, 1, 1679]]>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_fit_vectorizer(fit_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "-oqy9KjXRJ9A"
   },
   "source": [
    "## Generating n-grams\n",
    "\n",
    "As you saw in the lecture, the idea now is to generate the n-grams for each sentence in the corpus. So, for instance, if a vectorized sentence is given by `[45, 75, 195, 879]`, you must generate the following vectors:\n",
    "\n",
    "```Python\n",
    "[45, 75]\n",
    "[45, 75, 195]\n",
    "[45, 75, 195, 879]\n",
    "```\n",
    "## Exercise 2: n_grams_seqs\n",
    "\n",
    "Now complete the `n_gram_seqs` function below. This function receives the fitted vectorizer and the corpus (which is a list of strings) and should return a list containing the `n_gram` sequences for each line in the corpus.\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "- If you pass `vectorizer(sentence)` the result is not padded, whereas if you pass `vectorizer(list_of_sentences)`, the result won't be padded **only if you passed the argument `ragged = True`** in the TextVectorization setup.\n",
    "- This exercise directly depends on the previous one, because you need to pass the defined vectorizer as a parameter, so any error thrown in the previous exercise may propagate here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "id": "iy4baJMDl6kj",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: n_gram_seqs\n",
    "\n",
    "def n_gram_seqs(corpus, vectorizer):\n",
    "    \"\"\"\n",
    "    Generates a list of n-gram sequences\n",
    "    \n",
    "    Args:\n",
    "        corpus (list of string): lines of texts to generate n-grams for\n",
    "        vectorizer (tf.keras.layers.TextVectorization): an instance of the TextVectorization class adapted in the corpus\n",
    "    \n",
    "    Returns:\n",
    "        (list of tf.int64 tensors): the n-gram sequences for each line in the corpus\n",
    "    \"\"\"\n",
    "    input_sequences = []\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    for line in corpus:\n",
    "    \tsequence = vectorizer(line)\n",
    "    \tfor i in range(1, len(sequence)):\n",
    "    \t\tn_gram_sequence = sequence[:i+1]\n",
    "    \t\tinput_sequences.append(n_gram_sequence)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "DlKqW2pfM7G3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram sequences for first example look like this:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2,), dtype=int64, numpy=array([ 35, 489])>,\n",
       " <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  35,  489, 1259])>,\n",
       " <tf.Tensor: shape=(4,), dtype=int64, numpy=array([  35,  489, 1259,  164])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([  35,  489, 1259,  164,  230])>,\n",
       " <tf.Tensor: shape=(6,), dtype=int64, numpy=array([  35,  489, 1259,  164,  230,  582])>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function with one example\n",
    "first_example_sequence = n_gram_seqs([corpus[0]], vectorizer)\n",
    "\n",
    "print(\"n_gram sequences for first example look like this:\\n\")\n",
    "first_example_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0HL8Ug6UU0Jt"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "n_gram sequences for first example look like this:\n",
    "\n",
    "[<tf.Tensor: shape=(2,), dtype=int64, numpy=array([ 35, 489])>,\n",
    " <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  35,  489, 1259])>,\n",
    " <tf.Tensor: shape=(4,), dtype=int64, numpy=array([  35,  489, 1259,  164])>,\n",
    " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([  35,  489, 1259,  164,  230])>,\n",
    " <tf.Tensor: shape=(6,), dtype=int64, numpy=array([  35,  489, 1259,  164,  230,  582])>]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wtPpCcBjNc4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_gram sequences for next 3 examples look like this:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(2,), dtype=int64, numpy=array([  9, 935])>,\n",
       " <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  9, 935, 143])>,\n",
       " <tf.Tensor: shape=(4,), dtype=int64, numpy=array([  9, 935, 143, 369])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([  9, 935, 143, 369, 101])>,\n",
       " <tf.Tensor: shape=(6,), dtype=int64, numpy=array([  9, 935, 143, 369, 101, 171])>,\n",
       " <tf.Tensor: shape=(7,), dtype=int64, numpy=array([  9, 935, 143, 369, 101, 171, 207])>,\n",
       " <tf.Tensor: shape=(2,), dtype=int64, numpy=array([17, 23])>,\n",
       " <tf.Tensor: shape=(3,), dtype=int64, numpy=array([17, 23,  3])>,\n",
       " <tf.Tensor: shape=(4,), dtype=int64, numpy=array([  17,   23,    3, 1006])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([  17,   23,    3, 1006,   64])>,\n",
       " <tf.Tensor: shape=(6,), dtype=int64, numpy=array([  17,   23,    3, 1006,   64,   31])>,\n",
       " <tf.Tensor: shape=(7,), dtype=int64, numpy=array([  17,   23,    3, 1006,   64,   31,   51])>,\n",
       " <tf.Tensor: shape=(8,), dtype=int64, numpy=array([  17,   23,    3, 1006,   64,   31,   51,  803])>,\n",
       " <tf.Tensor: shape=(2,), dtype=int64, numpy=array([ 27, 315])>,\n",
       " <tf.Tensor: shape=(3,), dtype=int64, numpy=array([ 27, 315, 745])>,\n",
       " <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 27, 315, 745, 101])>,\n",
       " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([ 27, 315, 745, 101, 209])>,\n",
       " <tf.Tensor: shape=(6,), dtype=int64, numpy=array([ 27, 315, 745, 101, 209,  27])>,\n",
       " <tf.Tensor: shape=(7,), dtype=int64, numpy=array([ 27, 315, 745, 101, 209,  27, 286])>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function with a bigger corpus\n",
    "next_3_examples_sequence = n_gram_seqs(corpus[1:4], vectorizer)\n",
    "\n",
    "print(\"n_gram sequences for next 3 examples look like this:\\n\")\n",
    "next_3_examples_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EIzecMczU9UB"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "n_gram sequences for next 3 examples look like this:\n",
    "\n",
    "[<tf.Tensor: shape=(2,), dtype=int64, numpy=array([  9, 935])>,\n",
    " <tf.Tensor: shape=(3,), dtype=int64, numpy=array([  9, 935, 143])>,\n",
    " <tf.Tensor: shape=(4,), dtype=int64, numpy=array([  9, 935, 143, 369])>,\n",
    " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([  9, 935, 143, 369, 101])>,\n",
    " <tf.Tensor: shape=(6,), dtype=int64, numpy=array([  9, 935, 143, 369, 101, 171])>,\n",
    " <tf.Tensor: shape=(7,), dtype=int64, numpy=array([  9, 935, 143, 369, 101, 171, 207])>,\n",
    " <tf.Tensor: shape=(2,), dtype=int64, numpy=array([17, 23])>,\n",
    " <tf.Tensor: shape=(3,), dtype=int64, numpy=array([17, 23,  3])>,\n",
    " <tf.Tensor: shape=(4,), dtype=int64, numpy=array([  17,   23,    3, 1006])>,\n",
    " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([  17,   23,    3, 1006,   64])>,\n",
    " <tf.Tensor: shape=(6,), dtype=int64, numpy=array([  17,   23,    3, 1006,   64,   31])>,\n",
    " <tf.Tensor: shape=(7,), dtype=int64, numpy=array([  17,   23,    3, 1006,   64,   31,   51])>,\n",
    " <tf.Tensor: shape=(8,), dtype=int64, numpy=array([  17,   23,    3, 1006,   64,   31,   51,  803])>,\n",
    " <tf.Tensor: shape=(2,), dtype=int64, numpy=array([ 27, 315])>,\n",
    " <tf.Tensor: shape=(3,), dtype=int64, numpy=array([ 27, 315, 745])>,\n",
    " <tf.Tensor: shape=(4,), dtype=int64, numpy=array([ 27, 315, 745, 101])>,\n",
    " <tf.Tensor: shape=(5,), dtype=int64, numpy=array([ 27, 315, 745, 101, 209])>,\n",
    " <tf.Tensor: shape=(6,), dtype=int64, numpy=array([ 27, 315, 745, 101, 209,  27])>,\n",
    " <tf.Tensor: shape=(7,), dtype=int64, numpy=array([ 27, 315, 745, 101, 209,  27, 286])>]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_n_gram_seqs(n_gram_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "dx3V_RjFWQSu"
   },
   "source": [
    "Apply the `n_gram_seqs` transformation to the whole corpus and save the maximum sequence length to use it later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "laMwiRUpmuSd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_grams of input_sequences have length: 15355\n",
      "maximum length of sequences is: 11\n"
     ]
    }
   ],
   "source": [
    "# Apply the n_gram_seqs transformation to the whole corpus\n",
    "input_sequences = n_gram_seqs(corpus, vectorizer)\n",
    "\n",
    "# Save max length \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "\n",
    "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
    "print(f\"maximum length of sequences is: {max_sequence_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "2OciMdmEdE9L"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "n_grams of input_sequences have length: 15355\n",
    "maximum length of sequences is: 11\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "zHY7HroqWq12"
   },
   "source": [
    "## Exercise 3: pad_seqs\n",
    "\n",
    "Now code the `pad_seqs` function which will pad any given sequences to the desired maximum length. Notice that this function receives a list of sequences and should return a numpy array with the padded sequences. You may have a look at the documentation of [`tf.keras.utils.pad_sequences`](https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences). \n",
    "\n",
    "**NOTE**: \n",
    "\n",
    "- Remember to pass the correct padding method as discussed in the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cellView": "code",
    "deletable": false,
    "id": "WW1-qAZaWOhC",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: pad_seqs\n",
    "\n",
    "def pad_seqs(input_sequences, max_sequence_len):\n",
    "    \"\"\"\n",
    "    Pads tokenized sequences to the same length\n",
    "    \n",
    "    Args:\n",
    "        input_sequences (list of int): tokenized sequences to pad\n",
    "        maxlen (int): maximum length of the token sequences\n",
    "    \n",
    "    Returns:\n",
    "        (np.array of int32): tokenized sequences padded to the same length\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "\n",
    "    padded_sequences = np.array(tf.keras.utils.pad_sequences(input_sequences,\n",
    "                                                             maxlen=max_sequence_len,\n",
    "                                                             padding='pre'))\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "IqVQ0pb3YHLr"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,   35,  489],\n",
       "       [   0,    0,    0,   35,  489, 1259],\n",
       "       [   0,    0,   35,  489, 1259,  164],\n",
       "       [   0,   35,  489, 1259,  164,  230],\n",
       "       [  35,  489, 1259,  164,  230,  582]], dtype=int32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function with the n_grams_seq of the first example\n",
    "first_padded_seq = pad_seqs(first_example_sequence, max([len(x) for x in first_example_sequence]))\n",
    "first_padded_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "Re_avDznXRnU"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "array([[   0,    0,    0,    0,   35,  489],\n",
    "       [   0,    0,    0,   35,  489, 1259],\n",
    "       [   0,    0,   35,  489, 1259,  164],\n",
    "       [   0,   35,  489, 1259,  164,  230],\n",
    "       [  35,  489, 1259,  164,  230,  582]], dtype=int32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "j56_UCOBYzZt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    9,  935],\n",
       "       [   0,    0,    0,    0,    0,    9,  935,  143],\n",
       "       [   0,    0,    0,    0,    9,  935,  143,  369],\n",
       "       [   0,    0,    0,    9,  935,  143,  369,  101],\n",
       "       [   0,    0,    9,  935,  143,  369,  101,  171],\n",
       "       [   0,    9,  935,  143,  369,  101,  171,  207],\n",
       "       [   0,    0,    0,    0,    0,    0,   17,   23],\n",
       "       [   0,    0,    0,    0,    0,   17,   23,    3],\n",
       "       [   0,    0,    0,    0,   17,   23,    3, 1006],\n",
       "       [   0,    0,    0,   17,   23,    3, 1006,   64],\n",
       "       [   0,    0,   17,   23,    3, 1006,   64,   31],\n",
       "       [   0,   17,   23,    3, 1006,   64,   31,   51],\n",
       "       [  17,   23,    3, 1006,   64,   31,   51,  803],\n",
       "       [   0,    0,    0,    0,    0,    0,   27,  315],\n",
       "       [   0,    0,    0,    0,    0,   27,  315,  745],\n",
       "       [   0,    0,    0,    0,   27,  315,  745,  101],\n",
       "       [   0,    0,    0,   27,  315,  745,  101,  209],\n",
       "       [   0,    0,   27,  315,  745,  101,  209,   27],\n",
       "       [   0,   27,  315,  745,  101,  209,   27,  286]], dtype=int32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your function with the n_grams_seq of the next 3 examples\n",
    "next_3_padded_seq = pad_seqs(next_3_examples_sequence, max([len(s) for s in next_3_examples_sequence]))\n",
    "next_3_padded_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "3rmcDluOXcIU"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "array([[   0,    0,    0,    0,    0,    0,    9,  935],\n",
    "       [   0,    0,    0,    0,    0,    9,  935,  143],\n",
    "       [   0,    0,    0,    0,    9,  935,  143,  369],\n",
    "       [   0,    0,    0,    9,  935,  143,  369,  101],\n",
    "       [   0,    0,    9,  935,  143,  369,  101,  171],\n",
    "       [   0,    9,  935,  143,  369,  101,  171,  207],\n",
    "       [   0,    0,    0,    0,    0,    0,   17,   23],\n",
    "       [   0,    0,    0,    0,    0,   17,   23,    3],\n",
    "       [   0,    0,    0,    0,   17,   23,    3, 1006],\n",
    "       [   0,    0,    0,   17,   23,    3, 1006,   64],\n",
    "       [   0,    0,   17,   23,    3, 1006,   64,   31],\n",
    "       [   0,   17,   23,    3, 1006,   64,   31,   51],\n",
    "       [  17,   23,    3, 1006,   64,   31,   51,  803],\n",
    "       [   0,    0,    0,    0,    0,    0,   27,  315],\n",
    "       [   0,    0,    0,    0,    0,   27,  315,  745],\n",
    "       [   0,    0,    0,    0,   27,  315,  745,  101],\n",
    "       [   0,    0,    0,   27,  315,  745,  101,  209],\n",
    "       [   0,    0,   27,  315,  745,  101,  209,   27],\n",
    "       [   0,   27,  315,  745,  101,  209,   27,  286]], dtype=int32)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_pad_seqs(pad_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "rgK-Q_micEYA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padded corpus has shape: (15355, 11)\n"
     ]
    }
   ],
   "source": [
    "# Pad the whole corpus\n",
    "input_sequences = pad_seqs(input_sequences, max_sequence_len)\n",
    "\n",
    "print(f\"padded corpus has shape: {input_sequences.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "59RD1YYNc7CW"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "padded corpus has shape: (15355, 11)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ZbOidyPrXxf7"
   },
   "source": [
    "## Exercise 4: features_and_labels_dataset\n",
    "\n",
    "Before feeding the data into the neural network you should split it into features and labels. In this case the features will be the *padded n_gram sequences* with the **last element** removed from them and the labels will be the removed words.\n",
    "\n",
    "Complete the `features_and_labels_dataset` function below. This function expects the `padded n_gram sequences` as input and should return a **batched** [tensorflow dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) containing elements in the form (sentence, label). \n",
    "\n",
    "\n",
    "**NOTE**:\n",
    "- Notice that the function also receives the total of words in the corpus, this parameter will be **very important when one hot encoding the labels** since every word in the corpus will be a label at least once. The function you should use is [`tf.keras.utils.to_categorical`]((https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical)).\n",
    "- To generate a dataset you may use the function [tf.data.Dataset.from_tensor_slices](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#from_tensor_slices) after obtaining the sentences and their respective labels.\n",
    "- To batch a dataset, you may call the method [.batch](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch). A good number is `16`, but feel free to choose any number you want to, but keep it not greater than 64, otherwise the model may take too many epochs to achieve a good accuracy. Remember this is defined as a global variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cellView": "code",
    "deletable": false,
    "id": "9WGGbYdnZdmJ",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: features_and_labels\n",
    "def features_and_labels_dataset(input_sequences, total_words):\n",
    "    \"\"\"\n",
    "    Generates features and labels from n-grams and returns a tensorflow dataset\n",
    "    \n",
    "    Args:\n",
    "        input_sequences (list of int): sequences to split features and labels from\n",
    "        total_words (int): vocabulary size\n",
    "    \n",
    "    Returns:\n",
    "        (tf.data.Dataset): Dataset with elements in the form (sentence, label)\n",
    "    \"\"\"\n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Define the features and labels as discussed in the lectures\n",
    "    features = input_sequences[:, :-1]\n",
    "    labels = input_sequences[:, -1]\n",
    "    \n",
    "    # One hot encode the labels\n",
    "    one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)\n",
    "    \n",
    "    # Build the dataset with the features and one hot encoded labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features, one_hot_labels))\n",
    "    \n",
    "    # Batch the dataset with number of batches given by the global variable\n",
    "    batched_dataset = dataset.batch(NUM_BATCHES)\n",
    "    ### END CODE HERE ##\n",
    "    \n",
    "    return batched_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "23DolaBRaIAZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "\n",
      "N grams:\n",
      "\n",
      " [[   0    0    0    0   35]\n",
      " [   0    0    0   35  489]\n",
      " [   0    0   35  489 1259]\n",
      " [   0   35  489 1259  164]\n",
      " [  35  489 1259  164  230]]\n",
      "\n",
      "Label shape:\n",
      "\n",
      " (5, 3189)\n"
     ]
    }
   ],
   "source": [
    "# Test your function with the padded n_grams_seq of the first example\n",
    "dataset_example = features_and_labels_dataset(first_padded_seq, total_words)\n",
    "\n",
    "print(\"Example:\\n\")\n",
    "for features, label in dataset_example.take(1):\n",
    "    print(f\"N grams:\\n\\n {features}\\n\")\n",
    "    print(f\"Label shape:\\n\\n {label.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "7t4yAx2UaQ43"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "Example:\n",
    "\n",
    "N grams:\n",
    "\n",
    " [[   0    0    0    0   35]\n",
    " [   0    0    0   35  489]\n",
    " [   0    0   35  489 1259]\n",
    " [   0   35  489 1259  164]\n",
    " [  35  489 1259  164  230]]\n",
    "\n",
    "Label shape:\n",
    "\n",
    " (5, 3189)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_features_and_labels_dataset(features_and_labels_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now let's generate the whole dataset that will be used for training. In this case, let's use the [.prefetch](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch) method to speed up the training. Since the dataset is not that big, you should not have problems with memory by doing this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "GRTuLEt3bRKa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature shape: TensorSpec(shape=(None, 10), dtype=tf.int32, name=None)\n",
      "Label shape: TensorSpec(shape=(None, 3189), dtype=tf.float64, name=None)\n"
     ]
    }
   ],
   "source": [
    "# Split the whole corpus\n",
    "dataset = features_and_labels_dataset(input_sequences, total_words).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(f\"Feature shape: {dataset.element_spec[0]}\")\n",
    "print(f\"Label shape: {dataset.element_spec[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "xXSMK_HpdLns"
   },
   "source": [
    "**Expected Output:**\n",
    "\n",
    "```\n",
    "Feature shape: TensorSpec(shape=(None, 10), dtype=tf.int32, name=None)\n",
    "Label shape: TensorSpec(shape=(None, 3189), dtype=tf.float32, name=None)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "ltxaOCE_aU6J"
   },
   "source": [
    "## Exercise 5: create_model\n",
    "\n",
    "Now you should define a model architecture capable of achieving an accuracy of at least 80%.\n",
    "\n",
    "Some hints to help you in this task:\n",
    "\n",
    "- The first layer in your model must be an [Input](https://www.tensorflow.org/api_docs/python/tf/keras/Input) layer with the appropriate parameters, remember that your input are vectors with a fixed length size. Be careful with the size value you should pass as you've removed the last element of every input to be the label.\n",
    "\n",
    "- An appropriate `output_dim` for the first layer (Embedding) is 100, this is already provided for you.\n",
    "- A Bidirectional LSTM is helpful for this particular problem.\n",
    "- The last layer should have the same number of units as the total number of words in the corpus and a softmax activation function.\n",
    "- This problem can be solved with only two layers (excluding the Embedding and Input) so try out small architectures first.\n",
    "- 30 epochs should be enough to get an accuracy higher than 80%, if this is not the case try changing the architecture of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "cellView": "code",
    "deletable": false,
    "id": "XrE6kpJFfvRY",
    "tags": [
     "graded"
    ]
   },
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: create_model\n",
    "\n",
    "def create_model(total_words, max_sequence_len):\n",
    "    \"\"\"\n",
    "    Creates a text generator model\n",
    "    \n",
    "    Args:\n",
    "        total_words (int): size of the vocabulary for the Embedding layer input\n",
    "        max_sequence_len (int): length of the input sequences\n",
    "    \n",
    "    Returns:\n",
    "       (tf.keras Model): the text generator model\n",
    "    \"\"\"\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    model.add(tf.keras.Input(shape=(max_sequence_len-1,)))\n",
    "    model.add(tf.keras.layers.Embedding(input_dim=total_words, output_dim=EMBEDDING_DIM, input_length=max_sequence_len-1))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_UNITS, return_sequences=True)))\n",
    "    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(LSTM_UNITS)))\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(total_words, activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        metrics=['accuracy'],\n",
    "        loss='categorical_crossentropy', \n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    )\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell allows you to check the number of total and trainable parameters of your model and prompts a warning in case these exceeds those of a reference solution, this serves the following 3 purposes listed in order of priority:\n",
    "\n",
    "- Helps you prevent crashing the kernel during training.\n",
    "\n",
    "- Helps you avoid longer-than-necessary training times.\n",
    "- Provides a reasonable estimate of the size of your model. In general you will usually prefer smaller models given that they accomplish their goal successfully.\n",
    "\n",
    "**Notice that this is just informative** and may be very well below the actual limit for size of the model necessary to crash the kernel. So even if you exceed this reference you are probably fine. However, **if the kernel crashes during training or it is taking a very long time and your model is larger than the reference, come back here and try to get the number of parameters closer to the reference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "0IpX_Gu_gISk",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92mYour model has 1,833,001 total parameters and the reference is 2,000,000\u001b[92m. You are good to go!\n",
      "\n",
      "\u001b[92mYour model has 1,833,001 trainable parameters and the reference is 2,000,000\u001b[92m. You are good to go!\n"
     ]
    }
   ],
   "source": [
    "# Get the untrained model\n",
    "model = create_model(total_words, max_sequence_len)\n",
    "\n",
    "# Check the parameter count against a reference solution\n",
    "unittests.parameter_count(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions have shape: (16, 3189)\n"
     ]
    }
   ],
   "source": [
    "example_batch = dataset.take(1)\n",
    "\n",
    "try:\n",
    "\tmodel.evaluate(example_batch, verbose=False)\n",
    "except:\n",
    "\tprint(\"Your model is not compatible with the dataset you defined earlier. Check that the loss function and last layer are compatible with one another.\")\n",
    "else:\n",
    "\tpredictions = model.predict(example_batch, verbose=False)\n",
    "\tprint(f\"predictions have shape: {predictions.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "**Expected output:**\n",
    "\n",
    "```\n",
    "predictions have shape: (NUM_BATCHES, 3189)\n",
    "```\n",
    "\n",
    "Where `NUM_BATCHES` is the number of batches you have set to your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m All tests passed!\n"
     ]
    }
   ],
   "source": [
    "# Test your code!\n",
    "unittests.test_create_model(create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 8ms/step - accuracy: 0.0258 - loss: 6.9853\n",
      "Epoch 2/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0241 - loss: 6.2160\n",
      "Epoch 3/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0272 - loss: 5.9413\n",
      "Epoch 4/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0315 - loss: 5.7112\n",
      "Epoch 5/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0335 - loss: 5.5573\n",
      "Epoch 6/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0415 - loss: 5.4363\n",
      "Epoch 7/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0471 - loss: 5.2671\n",
      "Epoch 8/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0491 - loss: 5.2111\n",
      "Epoch 9/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0525 - loss: 5.0927\n",
      "Epoch 10/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0562 - loss: 4.9949\n",
      "Epoch 11/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0587 - loss: 4.9202\n",
      "Epoch 12/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0643 - loss: 4.8609\n",
      "Epoch 13/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0709 - loss: 4.7216\n",
      "Epoch 14/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0733 - loss: 4.6058\n",
      "Epoch 15/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0820 - loss: 4.5052\n",
      "Epoch 16/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.0915 - loss: 4.3938\n",
      "Epoch 17/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1004 - loss: 4.2626\n",
      "Epoch 18/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1110 - loss: 4.2046\n",
      "Epoch 19/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1199 - loss: 4.0960\n",
      "Epoch 20/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1317 - loss: 4.0110\n",
      "Epoch 21/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1387 - loss: 3.9226\n",
      "Epoch 22/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1548 - loss: 3.7666\n",
      "Epoch 23/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1717 - loss: 3.7104\n",
      "Epoch 24/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1819 - loss: 3.6100\n",
      "Epoch 25/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.1939 - loss: 3.5561\n",
      "Epoch 26/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.2072 - loss: 3.4543\n",
      "Epoch 27/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.2307 - loss: 3.3490\n",
      "Epoch 28/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.2510 - loss: 3.2037\n",
      "Epoch 29/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.2687 - loss: 3.1085\n",
      "Epoch 30/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.2900 - loss: 3.0129\n",
      "Epoch 31/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3026 - loss: 2.9443\n",
      "Epoch 32/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3260 - loss: 2.8084\n",
      "Epoch 33/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3518 - loss: 2.6687\n",
      "Epoch 34/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3735 - loss: 2.5843\n",
      "Epoch 35/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3969 - loss: 2.4825\n",
      "Epoch 36/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3915 - loss: 2.4742\n",
      "Epoch 37/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.3967 - loss: 2.4537\n",
      "Epoch 38/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.4214 - loss: 2.3198\n",
      "Epoch 39/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.4332 - loss: 2.2735\n",
      "Epoch 40/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.4450 - loss: 2.2017\n",
      "Epoch 41/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.4572 - loss: 2.1701\n",
      "Epoch 42/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.4733 - loss: 2.0793\n",
      "Epoch 43/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.4723 - loss: 2.0995\n",
      "Epoch 44/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.4915 - loss: 1.9839\n",
      "Epoch 45/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5325 - loss: 1.8322\n",
      "Epoch 46/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5340 - loss: 1.7857\n",
      "Epoch 47/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5324 - loss: 1.7934\n",
      "Epoch 48/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5438 - loss: 1.7602\n",
      "Epoch 49/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5379 - loss: 1.7754\n",
      "Epoch 50/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5587 - loss: 1.6808\n",
      "Epoch 51/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5722 - loss: 1.6297\n",
      "Epoch 52/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5875 - loss: 1.5572\n",
      "Epoch 53/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.5994 - loss: 1.5155\n",
      "Epoch 54/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6040 - loss: 1.4851\n",
      "Epoch 55/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6207 - loss: 1.4105\n",
      "Epoch 56/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6390 - loss: 1.3552\n",
      "Epoch 57/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6436 - loss: 1.3109\n",
      "Epoch 58/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6297 - loss: 1.3770\n",
      "Epoch 59/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6219 - loss: 1.3969\n",
      "Epoch 60/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6516 - loss: 1.2791\n",
      "Epoch 61/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6609 - loss: 1.2290\n",
      "Epoch 62/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6742 - loss: 1.2165\n",
      "Epoch 63/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.6768 - loss: 1.1846\n",
      "Epoch 64/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.6883 - loss: 1.1318\n",
      "Epoch 65/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7036 - loss: 1.0892\n",
      "Epoch 66/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7043 - loss: 1.0891\n",
      "Epoch 67/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7257 - loss: 1.0009\n",
      "Epoch 68/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7339 - loss: 0.9577\n",
      "Epoch 69/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7545 - loss: 0.9123\n",
      "Epoch 70/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7536 - loss: 0.9113\n",
      "Epoch 71/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7723 - loss: 0.8317\n",
      "Epoch 72/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7769 - loss: 0.8189\n",
      "Epoch 73/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.8250\n",
      "Epoch 74/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7838 - loss: 0.7786\n",
      "Epoch 75/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7799 - loss: 0.8066\n",
      "Epoch 76/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7745 - loss: 0.8025\n",
      "Epoch 77/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.7831 - loss: 0.7887\n",
      "Epoch 78/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7869 - loss: 0.7395\n",
      "Epoch 79/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7869 - loss: 0.7483\n",
      "Epoch 80/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7776 - loss: 0.8066\n",
      "Epoch 81/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7861 - loss: 0.7342\n",
      "Epoch 82/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7833 - loss: 0.7538\n",
      "Epoch 83/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7848 - loss: 0.7715\n",
      "Epoch 84/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7938 - loss: 0.7228\n",
      "Epoch 85/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8076 - loss: 0.6623\n",
      "Epoch 86/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8080 - loss: 0.6622\n",
      "Epoch 87/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8045 - loss: 0.6809\n",
      "Epoch 88/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.7971 - loss: 0.6953\n",
      "Epoch 89/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8029 - loss: 0.6866\n",
      "Epoch 90/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8114 - loss: 0.6509\n",
      "Epoch 91/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8250 - loss: 0.6077\n",
      "Epoch 92/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8320 - loss: 0.5782\n",
      "Epoch 93/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8116 - loss: 0.6424\n",
      "Epoch 94/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8205 - loss: 0.6205\n",
      "Epoch 95/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8215 - loss: 0.6104\n",
      "Epoch 96/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8386 - loss: 0.5665\n",
      "Epoch 97/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 9ms/step - accuracy: 0.8414 - loss: 0.5250\n",
      "Epoch 98/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8437 - loss: 0.5315\n",
      "Epoch 99/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8398 - loss: 0.5301\n",
      "Epoch 100/100\n",
      "\u001b[1m960/960\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 8ms/step - accuracy: 0.8540 - loss: 0.4875\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(dataset, epochs=100, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "gy72RPgly55q"
   },
   "source": [
    "**To pass this assignment, your model should achieve a training accuracy of at least 80%**. If your model didn't achieve this threshold, try training again with a different model architecture. Consider increasing the number of units in your `LSTM` layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "1fXTEO3GJ282",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get training and validation accuracies\n",
    "acc = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "\n",
    "# Get number of epochs\n",
    "epochs = range(len(acc))\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "fig.suptitle('Training performance - Accuracy and Loss')\n",
    "\n",
    "for i, (data, label) in enumerate(zip([acc,loss], [\"Accuracy\", \"Loss\"])):\n",
    "    ax[i].plot(epochs, data, label=label)\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel('epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "OjvED5A3qrn2"
   },
   "source": [
    "If the accuracy meets the requirement of being greater than 80%, then save the `history.pkl` file which contains the information of the training history of your model and will be used to compute your grade. You can do this by running the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "9QRG73l6qE-c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "wdsMszk9zBs_"
   },
   "source": [
    "## See your model in action\n",
    "\n",
    "After all your work it is finally time to see your model generating text. \n",
    "\n",
    "Run the cell below to generate the next 100 words of a seed text.\n",
    "\n",
    "After submitting your assignment you are encouraged to try out training for different amounts of epochs and seeing how this affects the coherency of the generated text. Also try changing the seed text to see what you get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "id": "6Vc6PHgxa6Hm",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help me Obi Wan Kenobi, you're my only hope vainly wit expressd find me whose view up aside sing fall on me we blind sing so more nearly took love doth hide me i alone back so me swearing am well hath write anew to greet the gracious even for me this viewest prove up my mind dost sing expressd be fall more nearly see thee grace me much oaths ill in me than his makeless fled best fitted sing life on things wit grave is back again back again when other more fire from up or gain is aright be fair child or fall in niggarding her brow\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Help me Obi Wan Kenobi, you're my only hope\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    # Convert the text into sequences\n",
    "    token_list = vectorizer(seed_text)\n",
    "    # Pad the sequences\n",
    "    token_list = tf.keras.utils.pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    # Get the probabilities of predicting a word\n",
    "    predicted = model.predict([token_list], verbose=0)\n",
    "    # Choose the next word based on the maximum probability\n",
    "    predicted = np.argmax(predicted, axis=-1).item()\n",
    "    # Get the actual word from the word index\n",
    "    output_word = vectorizer.get_vocabulary()[predicted]\n",
    "    # Append to the current text\n",
    "    seed_text += \" \" + output_word\n",
    "\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "id": "6r-X-HXtSc8N"
   },
   "source": [
    "**Congratulations on finishing this week's assignment!**\n",
    "\n",
    "You have successfully implemented a neural network capable of predicting the next word in a sequence of text!\n",
    "\n",
    "**We hope to see you in the next course of the specialization! Keep it up!**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "dlai_version": "1.2.0",
  "grader_version": "1",
  "jupytext": {
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
